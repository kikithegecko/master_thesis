\chapter{Related Work}
Casual interaction, which is the core topic of this thesis, has been explored by other researchers.

Pohl and Murray-Smith have researched casual interaction with everyday electronics like smartphones. They coined the term ``casual interaction'' in contrast to focused interaction, and described that in many situations in daily life, the user would not receive periodic feedback from the interacting device or not interact with it in a constant, uninterrupted fashion due to physical, social or mental reasons like wearing gloves in the winter or being exhausted after a day of work. Instead of giving up control over the device in such situations, the user should be able to control the level of focus to which they would like to engage  \cite{Pohl2013}. The underlying distinction between foreground and background interaction in context of technology has been introduced by Buxton in 1995, where he described improvements on telemetry systems \cite{Buxton1995}.

Interaction with intelligent lighting in public space as well as in the arts has been researched by Seitinger et. al. \cite{Seitinger2010} \cite{Seitinger2009}.

Wearable electronic devices have been very present in the recent years. From activity trackers like the Fitbit bracelets \cite{fitbit} to smart watches that are either universal like the Pebble \cite{pebble} or bound to a certain phone like Samsung's Galaxy Gear \cite{galaxygear}, various devices have aimed for a spot on the user's wrist. More recently, attempts to add ``social'' features to wrist-worn smart devices have been made. The iBand concept by Kanis et. al attempts to augment virtual social networks by merging their information about a person into real-world interactions with people \cite{Kanis2005}. As a commercial product, the Razer Nabu smart band can exchange contact information on a handshake among other features \cite{razernabu}.

Controlling devices in the smart home is mostly realized by trigger-action programming as discussed by Ur et. al. \cite{Ur2014}, and enabled using the IFTTT environment\cite{ifttt} or customized applications for smartphones or the \textit{Android Wear} middleware \cite{androidwear}.

Regarding new shapes and configurations of wrist-worn wearables, research has come up with concepts involving multiple displays that form the \textit{Facet} bracelet \cite{Lyons2012}, gesture-only input for interaction with the \textit{Gesture Watch} \cite{Kim2007}, the \textit{Snaplet} flexible touch display that changes its application according to its current shape \cite{Tarun2011} or a tiny worn sensor that uses the surrounding skin on the arm or any other body part as an input canvas for touch and gesture input \cite{Ni2009}.

For gesture recognition, two major algorithms that originate from the field of machine learning are very present in research projects. The Gesture and Activity Recognition Toolkit \textit{GART} has been developed by Lyons et. al. and is based on Hidden Markov Models \cite{Lyons2012}, it has been used by the aforementioned \textit{Gesture Watch}\cite{Kim2007} and the \textit{AirTouch}, an around-device gesture recognition device that gives tactical feedback \cite{Lee2011}. Several other gesture recognizing wearables implement Dynamic Time Warping, another algorithm from the field of machine learning \cite{Ashbrook2010} \cite{Liu2009}. In contrast to those computation-heavy and complex algorithms, Wobbrock et. al. have developed a simpler, geometry-based gesture recognizer for touch screen interaction \cite{Wobbrock2007} that was extended to 3D accelerometer data by Kratz and Rohs \cite{Kratz2010}. The recognizer was designed as easy to implement and functional even on embedded devices with limited computation capabilities.